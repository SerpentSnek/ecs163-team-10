<!doctype html>
<html style="width:100%;height:100%;">
<head>
    <meta charset="utf-8">
    <!-- <script src="https://d3js.org/d3.v6.js"></script> -->
    <!-- <script src="{{url_for('static', filename='script.js')}}"></script> -->
    <!-- <script src="https://d3js.org/d3-scale-chromatic.v1.min.js"></script> -->
    <!-- <link href="{{ url_for('static', filename='styles/style.css') }}" rel="stylesheet" type="text/html" > -->
    <link rel="stylesheet" href="../static/styles/style.css">
    <title>walkthrough portion</title>
</head>
<body>
  <h1>Part II: The walkthrough</h1>
  <section class="walkthrough">
    <div class="subsection1">
      <p>
      What makes someone drop out of college?
      To find out, we used <a href="https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success">this dataset</a> from the Polytechnic Institute of Portalegre, Portugal.
      Using Python's Seaborn library, we created the heatmap on the right to observe all correlations between our given features. The bluer the color, the more positive the correlation.
      <br><br>
      This is a lot of features! We should drop the ones with barely any correlation with our target feature. </p>
    </div>
    <img src="../static/img/first heatmap.png" alt="a heatmap with all features given by the dataset" id="firstHeatmap"/>
  </section>
  <section class="walkthrough">
    <div class="subsection1">
      <p>
        Getting rid of features with little to no correlation with the "Target" variable (the variable that tells us if a student dropped out, is enrolled, or will graduate), like "Inflation rate" and "GDP", we get this:
      </p>
    </div>
    <img src="../static/img/narrow heatmap.png"/>
  </section>
  <section class="walkthrough">
    <div class="subsection1">
      <p>
        Those 8 remaining features (excluding "Target") have the most correlations a student's performance! The following is a pairplot showing how each of these features relate to each other (1 = dropout, 2 = enrolled, 3 = graduate):
      </p>
    </div>
    <img src="../static/img/all correlation scatterplots.png"/>
  </section>
  <section class="walkthrough">
    <div class="subsection2">
      <p>
        Let's narrow this down to just two features so we can actually plot these features against each other. We'll use a technique called Principle Component Analysis, done through Python's Scikit-Learn library.
      </p>
      <div class="pcaImages">
        <img src="../static/img/pca graph.png"/>
        <img src="../static/img/variable influence.png"/>
      </div>
      <p>
        This essentially tells us that the two most influential features of all are the student's age at enrollment and what grade students receive for their second semester. You may have also noticed that the scatter plot resembles the "Age at enrollment" vs "Curricular units 2nd sem (grade)" subplot in the pairplot above.
      </p>
    </div>
  </section>
  <section class="walkthrough">
    <div class="subsection2">
      <p>
        But how similar are these students to each other? To get better insight, we used KMeans with 4 clusters. We decided on 4 based on the elbow plot method, which tells us the optimal number of clusters. For clarity, let's plot this with "Age at enrollment" vs "Curricular units 2nd sem (grade)":
      </p><br>
      <p>
        With this, we can assume that there are 4 distinct kinds of people within this university.
      </p>
      <div class="pcaImages">
        <img src="../static/img/kmeans without pca.png"/>
        <img src="../static/img/age vs 2nd sem grade.png"/>
      </div>
    </div>
  </section>
    <!-- <h1> ECS 163 Team 10 Final Project: Student Dropout Rates and ML Predictor </h1> -->
    <!-- <a href="{{url_for('ml')}}" class="button-style">goto ml site test</a> -->
    
    <!-- Container for the SVG -->
    <!-- <div id="graph-container" style="width: 800px; height: 600px; margin: auto;">
        <svg width="100%" height="100%" id="bubble"></svg>
    </div>    -->
    
</body>
</html>
